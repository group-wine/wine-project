---
title: "sommelieR"
author: "Seoyoon Cho, Paloma Hauser, Taylor Lagler, Mike Nodzenski, Bryce Rowland"
date: "4/10/2019"
output: 
  beamer_presentation:
    color: "seahorse"
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# create the datasets for training and testing for the group project
set.seed(13)

library(caret)
library(readr)
library(dplyr)
library(ggplot2)
library(data.table)
library(gridExtra)
library(Hmisc)
library(corrplot)
library(tidyverse)
library(kableExtra)
library(knitr)
library(devtools)

#install sommelieR
install_github("group-wine/sommelieR")
library(sommelieR)

#load the datasets 
data("red_test")
data("red_train")
data("white_test")
data("white_train")

# Data splitting and merging scripts can be found in Data folder

#--------------------------------------------------------------------#
# Data set up for boxplot code:
red_all =  fread("./data/winequality-red.csv",header=T)
red_all$quality <- as.factor(red_all$quality)
names(red_all) = gsub(" ", "_", names(red_all))

white_all =  fread("./data/winequality-white.csv",header=T)
white_all$quality <- as.factor(white_all$quality)
names(white_all) = gsub(" ", "_", names(white_all))

#--------------------------------------------------------------------#
# Data set up for RF classification by type code:
all_train = fread("./data/training_data/all_train.csv",header=T)
all_test = fread("./data/testing_data/all_test.csv",header=T)

x.train = as.data.frame(all_train[,1:11], ncol=11)
y.train = factor(all_train$type)

x.test = as.data.frame(all_test[,1:11], ncol=11)
y.test = factor(all_test$type)

#--------------------------------------------------------------------#
# Data set up for RF classification by quality code:
source("./R/cmPlot_function.R") # required to plot CMs

red_train = fread("./data/training_data/red_train.csv",header=T)
red_test = fread("./data/testing_data/red_test.csv",header=T)

white_train = fread("./data/training_data/white_train.csv",header=T)
white_test = fread("./data/testing_data/white_test.csv",header=T)

x.train.red = as.data.frame(red_train[,1:11], ncol=11)
y.train.red = factor(red_train$quality)

x.test.red = as.data.frame(red_test[,1:11], ncol=11)
y.test.red = factor(red_test$quality)

x.train.white = as.data.frame(white_train[,1:11], ncol=11)
y.train.white = factor(white_train$quality)

x.test.white = as.data.frame(white_test[,1:11], ncol=11)
y.test.white = factor(white_test$quality)

# group into low (3-4), mid (5-6) and high (7-9)
y.train.red.grp <- y.train.red
levels(y.train.red.grp)[1:2] <- "low"
levels(y.train.red.grp)[2:3] <- "mid"
levels(y.train.red.grp)[3:4] <- "high"

y.test.red.grp <- y.test.red
levels(y.test.red.grp)[1:2] <- "low"
levels(y.test.red.grp)[2:3] <- "mid"
levels(y.test.red.grp)[3:4] <- "high"

y.train.white.grp <- y.train.white
levels(y.train.white.grp)[1:2] <- "low"
levels(y.train.white.grp)[2:3] <- "mid"
levels(y.train.white.grp)[3:5] <- "high"

y.test.white.grp <- y.test.white
levels(y.test.white.grp)[1:2] <- "low"
levels(y.test.white.grp)[2:3] <- "mid"
levels(y.test.white.grp)[3:5] <- "high"

#--------------------------------------------------------------------#


```

## Introduction
* 2 datasets related to red and white Vinho Verde wines
* each contain 11 physiochemical variables
    + fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol
* 6,493 observations
* outcome variable: wine quality
    + ordinal variable ranging from 0-10
    + 0 is poor, 10 is excellent 
    + classes are unbalanced

## Project Aim
Is it possible to predict wine quality using some subset of the physiochemical variables?

## Looking At the Red Wine Data
```{r red.boxplots, echo=FALSE, warning=FALSE}
# red wine
grid.arrange(
  ggplot(red_all, aes(x = quality, y = fixed_acidity)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = volatile_acidity)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = citric_acid)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = residual_sugar)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = chlorides)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = free_sulfur_dioxide)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = total_sulfur_dioxide)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = density)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = pH)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = sulphates)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(red_all, aes(x = quality, y = alcohol)) +
    geom_boxplot()+geom_jitter(alpha = .25), ncol=4
)
```

## Looking At the White Wine Data
```{r white.boxplots, echo=FALSE, warning=FALSE}
# white wine
grid.arrange(
  ggplot(white_all, aes(x = quality, y = fixed_acidity)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = volatile_acidity)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = citric_acid)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = residual_sugar)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = chlorides)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = free_sulfur_dioxide)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = total_sulfur_dioxide)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = density)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = pH)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = sulphates)) +
    geom_boxplot()+geom_jitter(alpha = .25),
  ggplot(white_all, aes(x = quality, y = alcohol)) +
    geom_boxplot()+geom_jitter(alpha = .25), ncol=4
)
```

## Correlations- Red Wine
```{r red.correlations, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
# correlations and p-values by variable pairs
rcor_red <-rcorr(as.matrix(red_all[,1:11]))

# plot of correlations
corrplot(rcor_red$r, type="upper", order="hclust", tl.col = "black",
         p.mat = rcor_red$P, sig.level = 0.01, insig = "blank")
```

## Correlations- White Wine
```{r white.correlations, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
# correlations and p-values by variable pairs
rcor_white <-rcorr(as.matrix(white_all[,1:11]))

# plot of correlations
corrplot(rcor_white$r, type="upper", order="hclust", tl.col = "black",
         p.mat = rcor_white$P, sig.level = 0.01, insig = "blank")
```

## Methods
* linear model
* partial proportional odds model
* multinomial model
* random forests

## Variable Selection
For variable selection, we examined the correlations between predictors and considered best subsets found in R. For the likelihood based models, we included the following predictors:
  
  * red wine: volatile acidity, total sulfur dioxide, pH, alcohol, sulfates
* white wine: pH, density, volatile_acidity, residual_sugar, alcohol

## Results: Linear Model

## Results: Partial Proportional Odds Model (White Wine)

```{r}
library(psych)

#only 2 quality 9's, so collapsing 
white_train$quality <- ifelse(white_train$quality == 9, 8, white_train$quality)
white_test$quality <- ifelse(white_test$quality == 9, 8, white_test$quality)

beta.starts <- coef(lm(quality ~ alcohol+ pH + volatile.acidity + residual.sugar,
                       data = white_train))

white.partial.prop <- partial.prop.odds.mod(y ="quality", in.data = white_train,
                              prop.odds.formula = ~ alcohol+ pH + volatile.acidity,
                              beta.prop.odds.start = beta.starts[2:4],
                              non.prop.odds.formula = ~ residual.sugar,
                              beta.non.prop.odds.start = matrix(rep(beta.starts[5], 5), nrow = 1),
                              method = "BFGS",itnmax = 1000)

#note one case where we get a negative probability prediction 
white.partial.prop.preds <- predict(white.partial.prop, white_test)
negative.probs <- apply(white.partial.prop.preds, 1, function(x) any(x <= 0))
white.partial.prop.preds[negative.probs , ]
white_test[negative.probs, ]

#take most likely category as the winner 
white.preds <- apply(white.partial.prop.preds, 1, function(x) c(3:8)[which.max(x)])
white.obs <- white_test$quality
table(white.preds, white.obs)
prop.correct.preds <- sum(white.preds == white.obs)/length(white.obs)
cohen.kappa(cbind(white.preds, white.obs))

#fully proportional odds 
white.prop.odds <- partial.prop.odds.mod(y ="quality", in.data = white_train,
                              prop.odds.formula = ~ alcohol+ pH + volatile.acidity + residual.sugar,
                              beta.prop.odds.start = beta.starts[2:5],
                              method = "BFGS", itnmax = 1000)
white.prop.odds.preds <- predict(white.prop.odds, white_test)

#take most likely category as the winner 
white.po.preds <- apply(white.prop.odds.preds, 1, function(x) c(3:8)[which.max(x)])
table(white.po.preds, white.obs)
prop.po.preds <- sum(white.po.preds == white.obs)/length(white.obs)
cohen.kappa(cbind(white.po.preds, white.obs))

#library(ordinal)
#test2 <- clm(factor(quality) ~  alcohol+ pH + volatile.acidity, nominal = ~ residual.sugar,
#             data = white_train)


```


## Results: Partial Proportional Odds Model (Red Wine)

```{r}

beta.starts <- coef(lm(quality ~ alcohol+ pH + volatile.acidity + sulphates + total.sulfur.dioxide,
                       data = red_train))

#partial proportional odds model
red.parital.prop <- partial.prop.odds.mod(y ="quality", in.data = red_train,
                              prop.odds.formula = ~ alcohol + pH+ volatile.acidity + sulphates,
                              beta.prop.odds.start = beta.starts[2:5],
                              non.prop.odds.formula = ~total.sulfur.dioxide,
                              beta.non.prop.odds.start = matrix(rep(beta.starts[6], 5), nrow = 1),
                              method = "BFGS", itnmax = 1000)
red.partial.preds <- predict(red.parital.prop, red_test)
red.ppo.winners <-  apply(red.partial.preds, 1, function(x) c(3:8)[which.max(x)])
red.obs <- red_test$quality
table(red.ppo.winners, red.obs)
prop.ppo.correct.preds <- sum(red.ppo.winners == red.obs)/length(red.obs)
cohen.kappa(cbind(red.ppo.winners, red.obs))

#proportional odds model
red.prop.odds <- partial.prop.odds.mod(y ="quality", in.data = red_train,
                              prop.odds.formula = ~ alcohol + pH + volatile.acidity + sulphates
                              + total.sulfur.dioxide,
                              beta.prop.odds.start = beta.starts[2:6],
                              method = "BFGS", itnmax = 1000)
red.po.preds <- predict(red.prop.odds, red_test)
red.po.winners <-  apply(red.po.preds, 1, function(x) c(3:8)[which.max(x)])
table(red.po.winners, red.obs)
prop.po.correct.preds <- sum(red.po.winners == red.obs)/length(red.obs)
cohen.kappa(cbind(red.po.winners, red.obs))

#all non-proportional 
red.non.prop <- partial.prop.odds.mod(y ="quality", in.data = red_train,
                              non.prop.odds.formula = ~ alcohol + pH+ volatile.acidity + sulphates
                              + total.sulfur.dioxide,
                              beta.non.prop.odds.start = matrix(rep(beta.starts[2:6], each = 5), nrow = 5, 
                                                                byrow = T),
                              method = "BFGS", itnmax = 1000)
red.npo.preds <- predict(red.non.prop, red_test)
red.npo.winners <-  apply(red.npo.preds, 1, function(x) c(3:8)[which.max(x)])
table(red.npo.winners, red.obs)
prop.npo.correct.preds <- sum(red.npo.winners == red.obs)/length(red.obs)
cohen.kappa(cbind(red.npo.winners, red.obs))




```


## Results: Multinomial Model

## Results: Random Forests (wine type classification)
First, we merge the white and red wine datasets and use random forests to try to classify the wines into red or white

```{r merged.rf, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
# train random forest
trCtl <- trainControl(savePredictions=TRUE)
fit <- train(x.train, y.train, method="rf", trControl=trCtl)

# random forest training results
#fit$results

# use training model to predict y
y.pred <- predict(fit, x.test)

# results of rf on test data
cM = confusionMatrix(data=y.pred, reference=y.test)

# classification results (red vs white)
#cM$table
pred <- round(cM$overall[1:2], 4) # prediction accuracy and kappa
res <- round(diag(cM$table)/table(y.test), 4)*100 # percent correct into each type

results.type <- setNames(data.frame(matrix(ncol = 4, nrow = 1)),
                            c("Prediction Accuracy", "Kappa", "Red", "White"))
results.type[1,] <- c(pred,res)
rownames(results.type) = c("Random Forest")

kable(results.type, caption = "Classification Results for Wine Type", booktabs=T) %>%
  add_header_above(c(" ", "Overall Results" = 2, "Percent Correct by Category" = 2)) %>%
  kable_styling(latex_options = c("repeat_header", "scale_down"))
```

## Results: Random Forests (wine type classification)
```{r merged.rfplot, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
# classification results as a plot
class.table <- as.data.frame(cM$table)
class.table$Freq[class.table$Freq == 0] <-NA
ggplot(class.table, aes(x = Reference, y = Prediction, size = Freq, fill=Freq, label=Freq)) +
  scale_size(range=c(8,30)) + geom_label(na.rm=T) + theme_minimal() +
  scale_fill_continuous(low="red3", high="lightyellow") + guides(size=FALSE) +
  ggtitle("RF Classification of Wine Type") + theme(plot.title = element_text(hjust=.5, size=20))
```


## Results: Random Forests (red wine quality classification)
Next, we use random forests to classify each wine's wine quality score. We have 7 categories (scores 3-9) and we do this separately for the red and white wines.
```{r red.rf, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
source("./R/cmPlot_function.R") # required to plot CMs
# train random forest
trCtl <- trainControl(savePredictions=TRUE)
fit.red <- train(x.train.red, y.train.red, method="rf", trControl=trCtl)
fit.white <- train(x.train.white, y.train.white, method="rf", trControl=trCtl)

# random forest training results
#fit.red$results
#fit.white$results

# use training model to predict y
y.pred.red <- predict(fit.red, x.test.red)
y.pred.white <- predict(fit.white, x.test.white)

# results of rf on test data
cM.red = confusionMatrix(data=y.pred.red, reference=y.test.red)
cM.white = confusionMatrix(data=y.pred.white, reference=y.test.white)

# classification results (into quality score)
#cM.red$table
class.red <- as.data.frame(cM.red$table)
class.red$Freq[class.red$Freq == 0] <-NA

#cM.white$table
class.white <- as.data.frame(cM.white$table)
class.white$Freq[class.white$Freq == 0] <-NA

# classification results as a plot
cmPlot(class.red, "red", pred_first = TRUE,
"RF Classification of Quality for Red Wines")
#cmPlot(class.white, "white", pred_first = TRUE,
#       "RF Classification of Quality for White Wines")

# prediction accuracy by category
pred.red <- round(diag(cM.red$table)/table(y.test.red), 4)*100
pred.white <- round(diag(cM.white$table)/table(y.test.white), 4)*100

# prediction accuracy and kappa
res.red = round(cM.red$overall[1:2], 4)
res.white = round(cM.white$overall[1:2], 4) 
```

## Results: Random Forests (white wine quality classification)
```{r white.rf, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
cmPlot(class.white, "white", pred_first = TRUE,
"RF Classification of Quality for White Wines")
```

## Results: Random Forests (grouped red wine quality classification)
We now group wine quality into three categories: low (scores 3-4), medium (5-6), high (7-9), and try to classify the wines into these three categories.
```{r red.rf.grouped, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
# train random forest
fit.red.grp <- train(x.train.red, y.train.red.grp, method="rf", trControl=trCtl)
fit.white.grp <- train(x.train.white, y.train.white.grp, method="rf", trControl=trCtl)

# random forest training results
#fit.red.grp$results
#fit.white.grp$results

# use training model to predict y
y.pred.red.grp <- predict(fit.red.grp, x.test.red)
y.pred.white.grp <- predict(fit.white.grp, x.test.white)

# results of rf on test data
cM.red.grp = confusionMatrix(data=y.pred.red.grp, reference=y.test.red.grp)
cM.white.grp = confusionMatrix(data=y.pred.white.grp, reference=y.test.white.grp)

# classification results (into quality score)
#cM.red.grp$table
class.red.grp <- as.data.frame(cM.red.grp$table)
class.red.grp$Freq[class.red.grp$Freq == 0] <-NA

#cM.white.grp$table
class.white.grp <- as.data.frame(cM.white.grp$table)
class.white.grp$Freq[class.white.grp$Freq == 0] <-NA

# classification results as a plot
cmPlot(class.red.grp, "red", pred_first = TRUE,
"RF Classification of Grouped Quality for Red Wines")
#cmPlot(class.white.grp, "white", pred_first = TRUE,
#       "RF Classification of Grouped Quality for White Wines")

# prediction accuracy by category
pred.red.grp <- round(diag(cM.red.grp$table)/table(y.test.red.grp), 4)*100
pred.white.grp <- round(diag(cM.white.grp$table)/table(y.test.white.grp), 4)*100

# prediction accuracy and kappa
res.red.grp = round(cM.red.grp$overall[1:2], 4)
res.white.grp = round(cM.white.grp$overall[1:2], 4)
```
## Results: Random Forests (grouped white wine quality classification)
```{r white.rf.grouped,echo=FALSE, message=FALSE, warning=FALSE}
cmPlot(class.white.grp, "white", pred_first = TRUE,
"RF Classification of Grouped Quality for White Wines")
```

## Results: Random Forests with Subsampling (grouped red wine quality classification)
We now perform the same grouped classification, but with subsampling to balance the groups.

```{r red.rf.grouped.ss,echo=FALSE, message=FALSE, warning=FALSE}
# subsmaple training data based on minimum within group count
train.red.grp <- cbind(x.train.red, y.train.red.grp)
ns.red <- min(table(train.red.grp$y.train.red.grp))
train.red.grp.ss <- train.red.grp %>% group_by(y.train.red.grp) %>% sample_n(ns.red)
x.train.red.grp.ss <- as.data.frame(train.red.grp.ss[,1:11], ncol=11)
y.train.red.grp.ss <- factor(train.red.grp.ss$y.train.red.grp)

train.white.grp <- cbind(x.train.white, y.train.white.grp)
ns.white <- min(table(train.white.grp$y.train.white.grp))
train.white.grp.ss <- train.white.grp %>% group_by(y.train.white.grp) %>% sample_n(ns.white)
x.train.white.grp.ss <- as.data.frame(train.white.grp.ss[,1:11], ncol=11)
y.train.white.grp.ss <- factor(train.white.grp.ss$y.train.white.grp)

# train random forest
fit.red.grp.ss <- train(x.train.red.grp.ss, y.train.red.grp.ss, method="rf", trControl=trCtl)
fit.white.grp.ss <- train(x.train.white.grp.ss, y.train.white.grp.ss, method="rf", trControl=trCtl)

# random forest training results
#fit.red.grp.ss$results
#fit.white.grp.ss$results

# use training model to predict y
y.pred.red.grp.ss <- predict(fit.red.grp.ss, x.test.red)
y.pred.white.grp.ss <- predict(fit.white.grp.ss, x.test.white)

# results of rf on test data
cM.red.grp.ss <- confusionMatrix(data=y.pred.red.grp.ss, reference=y.test.red.grp)
cM.white.grp.ss <- confusionMatrix(data=y.pred.white.grp.ss, reference=y.test.white.grp)

# classification results (into quality score)
#cM.red.grp.ss$table
class.red.grp.ss <- as.data.frame(cM.red.grp.ss$table)
class.red.grp.ss$Freq[class.red.grp.ss$Freq == 0] <-NA

#cM.white.grp.ss$table
class.white.grp.ss <- as.data.frame(cM.white.grp.ss$table)
class.white.grp.ss$Freq[class.white.grp.ss$Freq == 0] <-NA

# classification results as a plot
cmPlot(class.red.grp.ss, "red", pred_first = TRUE,
"RF Classification of Grouped Quality for Red Wines \n Subsampled by Group")
# cmPlot(class.white.grp.ss, "white", pred_first = TRUE,
#        "RF Classification of Grouped Quality for White Wines \n Subsampled by Group")

# prediction accuracy by category
pred.red.grp.ss <- round(diag(cM.red.grp.ss$table)/table(y.test.red.grp), 4)*100
pred.white.grp.ss <- round(diag(cM.white.grp.ss$table)/table(y.test.white.grp), 4)*100

# prediction accuracy and kappa
res.red.grp.ss <- round(cM.red.grp.ss$overall[1:2],4)
res.white.grp.ss <- round(cM.white.grp.ss$overall[1:2],4)

```

## Results: Random Forests with Subsampling (grouped red wine quality classification)

```{r white.rf.grouped.ss,echo=FALSE, message=FALSE, warning=FALSE}
cmPlot(class.white.grp.ss, "white", pred_first = TRUE,
"RF Classification of Grouped Quality for White Wines \n Subsampled by Group")
```

## Comparison of Results: Red Wine, Ungrouped
```{r echo=FALSE, message=FALSE, warning=FALSE}
#-----------------------------------------------------------------------------#
#-----------------------------------------------------------------------------#
# Create Results Data Tables
# round results to 4 digits
# accuracy into categories as percent
# rename row and fill in data accordingly (add more rows if needed)
library(knitr)
library(kableExtra)
#-----------------------------------------------------------------------------#
# RED WINE NO GROUPING
results.red <- setNames(data.frame(matrix(ncol = 8, nrow = 4)),
c("Prediction Accuracy", "Kappa", "3", "4", "5", "6", "7", "8"))
rownames(results.red) <- c("Random Forest", "Method 2", "Method 3", "Method 4")

results.red[1,] <- c(res.red, pred.red)


#-----------------------------------------------------------------------------#
# WHITE WINE NO GROUPING
results.white <- setNames(data.frame(matrix(ncol = 9, nrow = 4)),
c("Prediction Accuracy", "Kappa", "3", "4", "5", "6", "7", "8", "9"))
rownames(results.white) <- c("Random Forest", "Method 2", "Method 3", "Method 4")

results.white[1,] <- c(res.white, pred.white)


#-----------------------------------------------------------------------------#
# RED WINE WITH GROUPING
results.red.grp <- setNames(data.frame(matrix(ncol = 5, nrow = 5)),
c("Prediction Accuracy", "Kappa", "Low", "Mid", "High"))
rownames(results.red.grp) <- c("Random Forest", "RF Subsampled",
"Method 3", "Method 4", "Method 5")

results.red.grp[1,] <- c(res.red.grp, pred.red.grp)
results.red.grp[2,] <- c(res.red.grp.ss, pred.red.grp.ss)


#-----------------------------------------------------------------------------#
# WHITE WINE WITH GROUPING
results.white.grp <- setNames(data.frame(matrix(ncol = 5, nrow = 5)),
c("Prediction Accuracy", "Kappa", "Low", "Mid", "High"))
rownames(results.white.grp) <- c("Random Forest", "RF Subsampled",
"Method 3", "Method 4", "Method 5")

results.white.grp[1,] <- c(res.white.grp, pred.white.grp)
results.white.grp[2,] <- c(res.white.grp.ss, pred.white.grp.ss)

#-----------------------------------------------------------------------------#
# Print out comparison tables created above
# Red wine no groups
kable(results.red, caption = "Comparison of Results for Red Wine", booktabs=T) %>%
add_header_above(c(" ", "Overall Results" = 2, "Percent Correct by Category" = 6)) %>%
kable_styling(latex_options = c("repeat_header", "scale_down"))

#-----------------------------------------------------------------------------#
```

## Comparison of Results: White Wine, Ungrouped
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Print out comparison tables created above

# White wine no groups
kable(results.white, caption = "Comparison of Results for White Wine", booktabs=T) %>%
add_header_above(c(" ", "Overall Results" = 2, "Percent Correct by Category" = 7)) %>%
kable_styling(latex_options = c("repeat_header", "scale_down"))
```

## Comparison of Results: Red Wine, Grouped
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Red wine grouped
kable(results.red.grp, caption = "Comparison of Results for Red Wine with Grouped Quality", booktabs=T) %>%
add_header_above(c(" ", "Overall Results" = 2, "Percent Correct by Category" = 3)) %>%
kable_styling(latex_options = c("repeat_header", "scale_down"))
```

## Comparison of Results: White Wine, Grouped
```{r echo=FALSE, message=FALSE, warning=FALSE}
# White wine grouped
kable(results.white.grp, caption = "Comparison of Results for White Wine with Grouped Quality", booktabs=T) %>%
add_header_above(c(" ", "Overall Results" = 2, "Percent Correct by Category" = 3)) %>%
kable_styling(latex_options = c("repeat_header", "scale_down"))
```

## Discussion   
(about interpretation or possible future directions) 




